import re
import csv
import time
import argparse
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup

def parse_player_data(script_text):
    data = {}
    patterns = {
        'fullname': r"var fullname = '(.*?)';",
        'currentrank': r"var currentrank = (\d+);",
        'peakrank': r"var peakrank = (\d+);",
        'dob': r"var dob = (\d+);",
        'ht': r"var ht = (\d+);",
        'country': r"var country = '(.*?)';",
        'elo_rating': r"var elo_rating = '(\d+)';"
    }
    
    for key, pattern in patterns.items():
        match = re.search(pattern, script_text)
        if match:
            data[key] = match.group(1)
    return data

def parse_match_history(soup):
    table = soup.find('table', {'id': 'recent-results'})
    if not table:
        print("‚ùå –¢–∞–±–ª–∏—Ü–∞ —Å –∏—Å—Ç–æ—Ä–∏–µ–π –º–∞—Ç—á–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ HTML")
        return [], []
    
    try:
        headers = [th.get_text(strip=True) for th in table.find('thead').find_all('th')]
        rows = []
        for tr in table.find('tbody').find_all('tr'):
            cells = [td.get_text(strip=True) for td in tr.find_all('td')]
            rows.append(cells)
        return headers, rows
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Ç–∞–±–ª–∏—Ü—ã: {e}")
        return [], []

def main(url):
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Selenium (Chrome –≤ headless-—Ä–µ–∂–∏–º–µ)
    options = Options()
    options.add_argument("--headless")  # –ó–∞–ø—É—Å–∫ –±–µ–∑ –æ—Ç–∫—Ä—ã—Ç–∏—è –±—Ä–∞—É–∑–µ—Ä–∞
    options.add_argument("--disable-blink-features=AutomationControlled")  # –û–±—Ö–æ–¥ –∑–∞—â–∏—Ç—ã –æ—Ç –±–æ—Ç–æ–≤
    options.add_argument("user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    
    try:
        print("üåê –ó–∞–≥—Ä—É–∂–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É...")
        driver.get(url)
        time.sleep(3)  # –ñ–¥—ë–º –∑–∞–≥—Ä—É–∑–∫–∏ JS
        
        # –ü–æ–ª—É—á–∞–µ–º HTML –ø–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è JavaScript
        html = driver.page_source
        soup = BeautifulSoup(html, 'html.parser')

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        with open('debug_selenium.html', 'w', encoding='utf-8') as f:
            f.write(soup.prettify())
        
        # –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö –∏–≥—Ä–æ–∫–∞
        player_data = {}
        script = soup.find('script', string=re.compile('var fullname'))
        if script:
            player_data = parse_player_data(script.text)
            print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∏–≥—Ä–æ–∫–∞: {player_data.get('fullname', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
        else:
            print("‚ùå –î–∞–Ω–Ω—ã–µ –∏–≥—Ä–æ–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        # –ü–∞—Ä—Å–∏–Ω–≥ –∏—Å—Ç–æ—Ä–∏–∏ –º–∞—Ç—á–µ–π
        match_headers, match_rows = parse_match_history(soup)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ CSV
        if player_data:
            with open('player_data.csv', 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=player_data.keys())
                writer.writeheader()
                writer.writerow(player_data)
        
        if match_headers and match_rows:
            with open('match_history.csv', 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow(match_headers)
                writer.writerows(match_rows)
            print("‚úÖ –ò—Å—Ç–æ—Ä–∏—è –º–∞—Ç—á–µ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ match_history.csv")
        else:
            print("‚ùå –ò—Å—Ç–æ—Ä–∏—è –º–∞—Ç—á–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ (–ø—Ä–æ–≤–µ—Ä—å—Ç–µ debug_selenium.html)")
    
    except Exception as e:
        print(f"üö® –û—à–∏–±–∫–∞: {e}")
    finally:
        driver.quit()  # –ó–∞–∫—Ä—ã–≤–∞–µ–º –±—Ä–∞—É–∑–µ—Ä

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('url', help='URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–≥—Ä–æ–∫–∞ –Ω–∞ TennisAbstract.com')
    args = parser.parse_args()
    main(args.url)